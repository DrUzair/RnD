
Big Data + Neural Networks overshadowing domain specific
feature engineering and making machines outsmart humans in our home ground of language and vision. 
Why are we needed at all ? 
Prepare for 'age of useless people'.

Machine Learning is domain dependent and trial-and-error descipline.
Domain-dependency: Solutions/Techniques/Insights that work for one domain (NLP) may not hold useful in other domain (Image/Video Processing)
Trial-and-Error: Every different problem need to pass through numerous iterations to find out best values for hyperparameters (learning-rate, neural network architechture, activation functions etc)

Even after getting a solution right, the real success (prediction performance) hinges of the condition the future (unseen) data should come from the same distribution as training data.

underfitting --> High bias
overfitting --> High variance
